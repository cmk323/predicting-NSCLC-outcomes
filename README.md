# predicting-NSCLC-outcomes
Using simulated clinical and genomic data to build and evaluate a predictive model of one-year survival after diagnosis with NSCLC.

## Background
Lung cancer is the leading cause of cancer-related deaths worldwide. In 2018, the United States is estimated to have had approximately 234,030 new diagnoses of lung cancer, with an estimated 154,050 deaths. As lung cancer is a highly heterogeneous disease with variable survival outcomes, there has been wide interest in developing prognostic models that integrate varying sources of patient information (e.g. demographic, clinical, genomic, imaging) to predict patient survival following diagnosis. An eventual goal for these models is to deploy them as part of decision support systems to facilitate improved decision making in routine clinical practice.

## Data Cleansing & Preprocessing
Several steps were taken to clean the data and preprocess it into a format which can be "understood" by a machine learning model. During an intitial exploration of the clinical data, several categorical columns stood out as those which may potentially contain inconsistencies in data entry, such as misspellings. For example, the **Stage** column contained one row in which the grade "IB" was entered using a different convention, "1B". Furthermore, two misspellings of "Right Upper Lobe" as "Righ Upper Lobe" in the **Primary.Site** column resulted in two separate categories being created for the same category. Fixing these errors helped improve data quality. Similarly, a discrepancy was identified in the **Grade** column, for which 96 rows contained values of "9". However, the data description notes that grade should range in value from 1-4. Because 96 rows occupies over 50% of the 190 row dataset, it was determined that this entire column should be dropped as the meaning of these "9" values cannot be deduced without consulting with individuals involved in data collection and entry.

Another important step in data cleansing was handling missing data. A substantial number of rows were identified with missing data for either the **N**, **M**, or **Tumor.Size** columns. Because the TNM System and tumor size intuitively seem like important prognostic factors, it would be illogical to drop these columns. Instead, all rows were preserved via mean imputation, in which `SimpleImputer()` was used to estimate the missing values using the mean. Mean imputation was used in this scenario due to time constraints. However, model accuracy could potentially be improved by using the TNM System to predict missing values of **T**, **N**, and **M**. Another potential strategy for estimating values of missing data in the **N**, **M**, or **Tumor.Size** columns is the implementation of `KNNImputer()`, which completes missing values using k-Nearest Neighbors.

In regards to preprocessing the data prior to building the model, one important step was to convert all categorical (string) data to numerical data, whether in the form of integers or Boolean flags. In order to accomplish this, the categories in **Stage** and **T** were simplified from a letter-number (e.x. "1a") ranking system to a solely numerical system (e.x. "1"). Additionally, one hot encoding was implemented to convert the categorical data in the **Histology** column as well as the at-risk genes of interest in the genomic data into new categorical columns with Boolean flags. For example, the three histological categories were divided into three new columns and appended to the dataframe, with a Boolean flag marking whether or not each histological feature was observed in a given patient. Similarly, three at-risk genes identified during exploratory data analysis were converted into separate categorical columns, with Boolean flags marking whether or not each patient was found via tumor sequencing to possess the gene variant of interest.

## Exploratory Data Analysis
Through exploratory data analysis of both the clinical and genomic data, a total of 16 features were selected to be used for the predictive model due to their correlation with survival time and cancer outcome, thus making them important prognostic factors.

The selected features are as follows:
- **Survival Months:** the followup time in months
- **Age:** the patient's age (in years) at diagnosis
- **Number of Primary Tumors**
- **T:** the size and extent of the primary tumor
- **N:** the number of nearby lymph nodes to which the cancer has spread
- **M:** Whether or not the cancer has metastasized, or spread from the primary tumor to other parts of the body
- **Radiation:** whether or not the patient has been exposed to radiation treatment protocols
- **Stage:** stage at diagnosis
- **Tumor Size:** the size of the primary tumor
- **Both Lungs:** whether the cancer is present in only one or both of the patient's lungs
- **Adenocarcinoma:** whether or not the patient possesses histological features of adenocarcinoma
- **Large-cell carcinoma:** whether or not the patient possesses histological features of Large-cell carcinoma
- **Squamous cell carcinoma:** whether or not the patient possesses histological features of Squamous cell carcinoma
- **TP53_Col1:** whether or not the patient possesses this TP53 gene variant 
- **KRAS_Col1:** whether or not the patient possesses this KRAS gene variant
- **CDKN2A:** whether or not the patient possesses this CDKN2A gene variant

In regards to the gene variants of interest, genomic analysis revealed that mutations in TP53, KRAS, and CDKN2A genes are not only the most prevalent gene mutations in the genomic dataset but are also correlated with poor prognosis. The prognostic influence of these gene variants was determined via examining the survival rate of patients with these gene variants, as those patients with mutations in TP53, KRAS, and CDKN2A were found to have survival rates of 26%, 24%, and 6.7%, respectively. The cancer-causing effects of mutations in these specific genes were confirmed via a quick literature search on the topic, thus validating their use as categorical features in the predictive model.

In regards to feature engineering, the **Both Lungs** feature was engineered from the **Primary.Site** data due to the fact that there was no obvious correlation observed between primary site and cancer outcome with the exception of patients with cancer in both lungs. While the sample size for this patient population was quite small at only 5 rows, it logically follows that patients with cancer in both lungs likely have substantially poorer prognosis than those with cancer only in one portion of one lung. Thus, this feature was engineered to make more effective use of the data in the column. Because most cancers are not caused by a single mutated gene but rather a combination of gene variants, model accuracy could potentially be improved by engineering gene network features. Such gene network features were not investigated due to time constraints.

## Model Building & Validation
Because this model is tasked with predicting a discrete value after a given time step (alive or deceased), a classification algorithm is best suited for this task. **Classification** is broadly defined as a problem of identifying which set of categories a new observation belongs to. Thus, the model can help predict, given clinical and genomic data, which outcome class a patient might belong to after a 12-month period. 

One of many classification techniques, **random forest** classification algorithms are generally well suited for big data classification. Random forest classification works via the operation of a large ensemble of individual decision trees. After each individual decision tree in the forest produces a class prediction, the class with the most votes forms the overall model's prediction. Compared to a simple decision tree, random forest classification algorithms avoid and prevent overfitting through this usage of multiple trees.

This implementation of random forest classification uses the `sklearn.RandomForestClassifer`. Random forest classification was chosen as the ideal classification algorithm with which to build this model due to the ease of hyperparamater tuning and its ability to avoid overfitting. Additionally, a quick literature seach revealed that random forest classification is commonly used for similar modeling tasks of predicting cancer outcomes from genomic and clinical data in other studies.

After hyperparameter tuning, the ideal `test_size` was determined to be 0.20 and the ideal `n_estimators` was determined to be 100. While lower numbers of estimators were initially tested to avoid issues of overfitting, K Folds cross-validation confirmed minimal changes in mean absolute error resulted from increasing the number of estimators from 10 to 100. Similarly, a conventional 80/20 train/test split was determined to yield the highest accuracy at minimal cost to mean absolute error. The entropy criterion for `RandomForestClassifier()` was selected in the hopes of providing better results. Given the relatively small size of this dataset at 190 rows, the performance cost of using entropy instead of gini is minimal.

As mentioned above, K Folds cross-validation using `Kfold()` was used to investigate whether or not the model was overfitted. K Folds works by splitting the dataset into **k** subsets, training the model **k** times on different training sets, and testing the model **k** times on different test sets. Mean Aboslute Error (MAE) for the training and test sets can then be calculated in order to determine if the model is overfitted. Ultimately, it was determined that model was not overfitted due to the fact that the test MAE ranged from between 0.06 and 0.18.

The accuracy of the model was assessed using a combination of the built-in `sklearn` metric `accuracy-score()` as well as a confusion matrix. After hyperparameter tuning, the model was able to predict outcomes with 89% accuracy. Notably, the confusion matrix revealed that the model had a very high rate of true positives.

## Next Steps
With additional time and domain expertise, the accuracy of the model could likely be improved. While only random forest classification was used in this investigation, it would be worthwhile to compare other algorithms such as logistic regression, Naive Bayes, K-Nearest Neighbors, and Support Vector Machine. Ideally, multiple different models could be implemented and the predictions of which used to generate a final prediction using a custom ensemble method with weighting. As mentioned previously, model accuracy could also be improved through the implementation of more features, such as gene networks and tumor grade. Finally, accuracy may be improved through more sophisticated methods of imputing missing data, such as through KNN imputation.
